\documentclass[10pt,a4paper]{report}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[parfill]{parskip}
\usepackage{hyperref}
\usepackage{color}

\DeclareMathOperator*{\argmin}{\arg\!\min}

\begin{document}
\title{Neural Uncertainty}
\author{Max Cohen}

\chapter{Model definition}
\section{Notations}
We consider the prediction task of a set of observations $(y^1, \cdots y^T)$ given a set of input $(u^1, \cdots u^T)$.

\section{Model}
We define a $L$ layer RNN followed by a fully connected layer. At time step $t$,

\begin{equation*}
        \left\{
        \begin{aligned}
                y_{t+1}   & = \tanh(W_y x_{t+1}^L + b_y)                                                               \\
                x_{t+1}^l & = \tanh(W_{xx}^l x^{l}_{t} + W_{xu}^l x^{l-1}_{t+1} + b_x^l) \quad \forall 1 \leq l \leq L \\
        \end{aligned}
        \right.
\end{equation*}

with $x_{t}^0 \equiv u_{t} \; \forall t$ and $x_{0}^l \equiv 0 \; \forall 1 \leq l \leq L$ .

Let's consider the weights of the last RNN and fully connected layers as $\theta \equiv (W_{xx}^L, W_{xu}^L, b_x^L, W_y, b_y)$.
We can define a new matrix $x_t$ at each time step corresponding to the concatenation of all RNN layers: $x_t \equiv (x_t^1 \cdots x_t^L)$.
We also introduce two sequences of random noises as i.i.d real valued random variables $\epsilon$ and $\eta$, with covariance matrices $\Sigma_y$ and $\Sigma_x$.
We can now write our model in terms of two functions $f$ and $g$ as:

\begin{equation}
        \left\{
        \begin{aligned}
                y_t     & = f_\theta(x_t) + \epsilon_t            & \text{observation model} \\
                x_{t+1} & = g_\theta(x_{t}, u_{t+1}) + \eta_{t+1} & \text{state model}       \\
        \end{aligned}
        \right.
\end{equation}

In the following section, we will focus on maximizing the joint log likelihood
\begin{align}
        \log \; p_{\theta}(X_{0:T}, y_{0:T}, u_{0:T})
        \label{log_likelihood}
\end{align}

\section{Minimization}
We can start by developing the log likelihood:

\begin{align*}
        \log p_{\theta}(X_{0:T}, y_{0:T}, u_{0:T}) & = \frac{1}{T} \log\left(p_\theta(x_0)p_\theta(y_0 | x_0)\prod_{k=1}^{T} p_{\theta}(x_k | x_{k-1}, u_k) p_{\theta}(y_k | x_k)\right)                             \\
                                                   & = \frac{1}{T} \log p_\theta(x_0) + \frac{1}{T} \sum_{k=1}^{T} \log \; p_{\theta}(x_k | x_{k-1}, u_k) + \frac{1}{T} \sum_{k=0}^{T} \log \; p_{\theta}(y_k | x_k) \\
                                                   & = \frac{1}{T} \log p_\theta(x_0) -\frac{1}{2} \log|\Sigma_x| -\frac{1}{2} \log|\Sigma_y| + Cst                                                                  \\
                                                   & - \frac{1}{2T} \sum_{k=1}^{T}(x_k - g_\theta(x_{k-1}, u_{k}))' \Sigma_x^{-1} (x_k - g_\theta(x_{k-1}, u_{k}))                                                   \\
                                                   & - \frac{1}{2T} \sum_{k=0}^{T}(y_k - f_\theta(x_k))' \Sigma_y^{-1} (y_k - f_\theta(x_k))                                                                         \\
\end{align*}

We aim at maximizing \ref{log_likelihood} by gradient descent, by leveraging fisher's identity:
$$
        \nabla \log p_\theta(x_{0:T}, y_{0:T}, u_{0:T}) = \mathbb{E}_\theta \left[ \nabla\log p_\theta(x_{0:T}, y_{0:T}, u_{0:T}) | Y_{0:T} \right]
$$
In order to approximate this expectation, we need to sample from the posterior distribution $p_\theta(x|y)$.
In Section~\ref{sec:smc}, we detail a Sequential Monte Carlo approach to this end.
In Section~\ref{sec:gradient_descent}, we describe the algorithm to train our model through gradient descent.


\section{Sequential Monte Carlo Approach}
\label{sec:smc}

\subsection{Filter}
In order to compute the conditional expectations in the previous expressions, we will iteratively sample trajectories $\xi_{1:T}^i$ associated with weights $\omega^i$ with respect to the density $p_\theta(x | y)$, using a sequential Monte Carlo particle filter.

At time step $k=0$, $(\xi_0^l)_{l=1}^N$ are sampled independently from the first hidden state, and associated with sampling weights proportional to the observation density $q_\theta$:
\begin{align*}
        \xi_0^i    & \sim \mathcal{N}(x_0, \Sigma_x) \\
        \omega_0^i & \sim q_\theta(\xi_0^i)
\end{align*}

At time step $k+1$, we sample indices $I$ of the particles to propagate, based on their previous weights.
After propagation, particles weights are computed following the observation density function:
$$\mathbb{P}(I_{k+1}^i=j) = \omega_k^j \quad \forall 1 \leq j \leq N$$
$$\omega_{k+1}^i \sim q_\theta(\xi_{k+1}^i)$$

\subsection{Smoother}
Using the poor man filter, we get $N$ trajectories:
$$\xi_{1:k+1}^{i} = (\xi_{1:k}^{I_{k+1}^i}, \xi_{k+1}^i)$$

\subsection{Approximation}
We can now approximate this conditional expectation for any measurable bounded function $h$:
\begin{align*}
        \mathbb{E}_\theta \left[ h(x) | y_{1:T} \right] = \sum_{i=1}^N \omega_T^i h(\xi_{0:T}^i)
\end{align*}

\section{Gradient descent}
\label{sec:gradient_descent}

\subsection{Forward pass}
During the forward pass, we generate a set of $N$ particles under the law $p(x|y)$ for fixed values of $\theta$, $\Sigma_x$ and $\Sigma_y$.
We initialize the sequence with a initial hidden state sampled from the noise's distribution.
$$
        x^i_0 \sim \mathcal{N}(0, \Sigma_x)
$$
In order to predict each new time step $k+1$, particles from the previous step are attributed weights $\omega_k^i$ proportionally to the density probability around the targeted value $y_k$.

$$\omega_k^i \sim \exp(-\frac{1}{2}(y_k - f_{\theta_p}(x_k^i))'\Sigma^{-1}_{y, p}(y_k - f_{\theta_p}(x_k^i)))$$
We then select a new population from these particles indexed by $I_{k+1}^i$, based on their weights.
$$\mathbb{P}(I_{k+1}^i=j) = \omega_k^j \quad \forall 1 \leq j \leq N$$
The current hidden state is computed for the selected particles.
$$x^i_{k+1} = g_\theta(x_k^{I_{k+1}^i}, u_{k+1}) + \eta^i_{k+1}$$

\subsection{Loss function}
Considering that we have computed a set of $N$ trajectories $(\xi^i_{0:T}),\;1 \leq i \leq N$, associated with weights $(\omega^i)$, we can approximate the gradient of the log likelihood by computing the gradient of:
\begin{align*}
        \mathbb{J}(\theta) & = \log |\Sigma_x| + \log |\Sigma_y|                                                                                                        \\
                           & + \frac{1}{T}\sum_{k=1}^T \sum_{i=1}^N \omega^i (y_k - f_\theta(\xi_k^i))' \Sigma_y^{-1} (y_k - f_\theta(\xi_k^i))                         \\
                           & + \frac{1}{T}\sum_{k=0}^T \sum_{i=1}^N \omega^i (\xi_k^i - g_\theta(\xi_{k-1}^i, u_k))'\Sigma_x^{-1}(\xi_k^i - g_\theta(\xi_{k-1}^i, u_k))
\end{align*}

\subsection{Backward pass}
During this step, each parameter of the model is updated by gradient descent.
\end{document}
