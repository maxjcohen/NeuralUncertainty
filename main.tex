\documentclass[10pt,a4paper]{report}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[parfill]{parskip}
\usepackage{hyperref}

\DeclareMathOperator*{\argmin}{\arg\!\min}

\begin{document}
\title{Neural Uncertainty}
\author{Max Cohen}

\chapter{Model definition}
\section{Notations}
We consider the prediction task of a set of observations $(y^1, \cdots y^T)$ given a set of input $(u^1, \cdots u^T)$.

\section{Model}
We define a $L$ layer RNN followed by a fully connected layer. At time step $t$,

\begin{equation*}
    \left\{
    \begin{aligned}
        y_{t+1}   & = \tanh(W_y x_{t+1}^L + b_y)                                                               \\
        x_{t+1}^l & = \tanh(W_{xx}^l x^{l}_{t} + W_{xu}^l x^{l-1}_{t+1} + b_x^l) \quad \forall 1 \leq l \leq L \\
    \end{aligned}
    \right.
\end{equation*}

with $x_{t}^0 \equiv u_{t} \; \forall t$ and $x_{0}^l \equiv 0 \; \forall 1 \leq l \leq L$ .

Let's consider the weights of the last RNN and fully connected layers as $\theta \equiv (W_{xx}^L, W_{xu}^L, b_x^L, W_y, b_y)$. We can define a new matrix $y_t$ at each time step corresponding to the concatenation of all RNN layers: $x_t \equiv (x_t^1 \cdots x_t^L)$. We also introduce two sequences of random noises as i.i.d real valued random variables $\epsilon$ and $\eta$. We can now write our model in terms of two functions $f$ and $g$ as:

\begin{equation}
    \left\{
    \begin{aligned}
        y_{t+1} & = f_\theta(x_{t+1}) + \epsilon_{t+1}    & \text{observation model} \\
        x_{t+1} & = g_\theta(x_{t}, u_{t+1}) + \eta_{t+1} & \text{state model}       \\
    \end{aligned}
    \right.
\end{equation}

In the following section, we will focus on minimizing the log likelihood
\begin{align}
    \log \; p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T})
    \label{log_likelihood}
\end{align}

\section{Minimization}

In order to minimize \ref{log_likelihood}, we apply an EM strategy. Let $\mu_p = (\theta_p, \Sigma_{x, p}, \Sigma_{y, p})$, we will compute at each EM step:
\begin{align}
    Q(\hat \mu_p, \mu) & = \mathop{\mathbb{E}_{\hat \mu_p}} \left[ \log \; p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T}) | y_{1:T} \right]
\end{align}

We can start by developing the log likelihood:

\begin{align*}
    \log p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T}) & = \frac{1}{T} \log\left(\prod_{k=1}^{T} p_{\mu}(x_k | x_{k-1}, u_k) p_{\mu}(y_k | x_k)\right)                                                                               \\
                                            & = \frac{1}{T} \sum_{k=1}^{T} \log \; p_{\mu}(x_k | x_{k-1}, u_k) + \log \; p_{\mu}(y_k | x_k)                                                                               \\
                                            & = \frac{1}{T} \sum_{k=1}^{T} \log \left(\det(2\pi\Sigma_x)^{-1/2} \exp(-\frac{1}{2}(x_k - g_\theta(x_{k-1}, u_{k}))^T \Sigma_x^{-1} (x_k - g_\theta(x_{k-1}, u_{k}))\right) \\
                                            & + \log \left(det(2\pi\Sigma_y)^{-1/2} \exp(-\frac{1}{2}(y_k - f_\theta(x_k))^T \Sigma_y^{-1} (y_k - f_\theta(x_k))\right)                                                   \\
                                            & = -\frac{1}{2} \log|\Sigma_x| -\frac{1}{2} \log|\Sigma_y|                                                                                                                   \\
                                            & - \frac{1}{2T} \sum_{k=1}^{T}(x_k - g_\theta(x_{k-1}, u_{k}))^T \Sigma_x^{-1} (x_k - g_\theta(x_{k-1}, u_{k}))                                                              \\
                                            & - \frac{1}{2T} \sum_{k=1}^{T}(y_k - f_\theta(x_k))^T \Sigma_y^{-1} (y_k - f_\theta(x_k))                                                                                    \\
\end{align*}

We will jointly update $\Sigma_x$, $\Sigma_y$ and $\theta$ iteratively. We can start by computing the explicit form of the minimum of both covariance matrices.

For $\Sigma_y$, we search the zeros of the derivate of the convex function $\Sigma_y \mapsto p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T})$.

\begin{align*}
    \frac{\partial p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T})}{\partial \Sigma_y^{-1}} & = \frac{1}{2} \Sigma_y - \frac{1}{2T} \sum_{k=1}^T (x_k - f_{\theta}(x_{k})) \cdot (x_k - f_{\theta}(x_{k}))'
\end{align*}

\begin{align*}
    \frac{\partial p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T})}{\partial \Sigma_y^{-1}} = 0 & \implies \Sigma_y = \frac{1}{T}\sum_{k=1}^T (y_k - f_{\theta}(x_k))(y_k - f_{\theta}(x_k))'                   \\
    \frac{\partial p_{\mu}(X_{1:T}, y_{1:T}, u_{1:T})}{\partial \Sigma_x^{-1}} = 0 & \implies \Sigma_x = \frac{1}{T}\sum_{k=1}^T (x_k - g_{\theta}(x_{k-1}, u_k))(x_k - g_{\theta}(x_{k-1}, u_k))'
\end{align*}


We now have an expression for minimizing both $\Sigma$ matrices given a value of $\theta$, but we can't compute an explicit form for minimizing $\theta$. We can identify two approaches to jointly minimizing $\mu$:
\begin{enumerate}
    \item At each step of the EM algorithm, we can compute the maximum expectation for both covariant matrices given the previous value of $\theta$, then approximate the new $\theta$ by minimizing an $\argmin$, through gradient descent for example.
          \begin{align*}
              \Sigma_{y, p+1} & = \frac{1}{T}\sum_{k=1}^T \mathbb{E}_{\hat \mu_p} \left[ (y_k - f_{\theta_p}(x_k))(y_k - f_{\theta_p}(x_k))' | y_{1:T} \right]                   \\
              \Sigma_{x, p+1} & = \frac{1}{T}\sum_{k=1}^T \mathbb{E}_{\hat \mu_p} \left[ (x_k - g_{\theta_p}(x_{k-1}, u_k))(x_k - g_{\theta_p}(x_{k-1}, u_k))' | y_{1:T} \right] \\
              \theta_{p+1}    & = \argmin_{\theta} \frac{1}{T}\sum_{k=1}^T \mathbb{E}_{\hat \mu_p} [ (y_k - f_{\theta_p}(x_k))' \Sigma_{y, p+1}^{-1} (y_k - f_{\theta_p}(x_k))   \\
                              & + (x_k - g_{\theta_p}(x_{k-1}, u_k)'\Sigma_{x, p+1}^{-1}(x_k - g_{\theta_p}(x_{k-1}, u_k)) | y_{1:T} ]
          \end{align*}
    \item We can also ignore the explicit expression for the covariant matrices, and approximate both $\theta$ and $\Sigma$ by gradient descent at each time step. Although we're putting aside a valuable result about $\Sigma$, this method could prove more efficient from an implementation perspective.
\end{enumerate}


\section{Sequential Monte Carlo Approach}
We approximate the expectation conditional to the observations by using a particle filter. We sample $M$ trajectories $\xi_{1:T}^m$ associated with the weight $\omega_T^m$. At each time step $k$, we have:
\begin{align*}
    \Phi_k^M[h] & = \mathbb{E}_{\hat \mu_p} \left[ h(x_k) | y_{1:T} \right] \\
                & = \frac{1}{\Omega_T^M} \sum_{m=1}^M \omega_T^m h(\xi_k^m)
\end{align*}
For all $h$ measurable bounded, where $\Omega_T^M = \sum_{m=1}^M \omega_T^m$. In the following sections, we consider that the particles weights sum at 1.

\section{Gradient descent}
At each iteration of the EM algorithm, we start by generating a set of particles under the law $p(x|y)$, that allows us to compute a explicit value for the expectation. We can then minimize this expectation, in order to approximate the new $\theta$ candidate, using a gradient descent.

\begin{align*}
    \theta_{p+1} & = \argmin_{\theta} \frac{1}{T}\sum_{k=1}^T \sum_{m=1}^M \omega_T^m (y_k - f_{\theta_p}(\xi_k^m))' \Sigma_{y, p+1}^{-1} (y_k - f_{\theta_p}(\omega_k^m)) \\
                 & + \omega_T^m (\xi_k^m - g_{\theta_p}(\xi_{k-1}^m, u_k)'\Sigma_{x, p+1}^{-1}(\xi_k^m - g_{\theta_p}(\xi_{k-1}^m, u_k))
\end{align*}

\end{document}